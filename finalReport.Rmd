---
title: "COD Reproducibility Report"
output:
  html_document:
    toc: true
    toc_float: true
---

#### Article ID: leydV
#### Pilot: Gustav Nilsonne
#### Start date: June 13 2017
#### End date: Jun 14 2017
#### Co-Pilot: Mike Frank
#### Final verification: Tom Hardwicke
#### Date: Nov 11 2017

-------

#### Methods summary: 
This paper investigated whether a single exposure to an unlikely false solution before the presentation of a card trick can prevent participants from finding the real (more obvious) solution, even if they were invited to search for an alternative solution. One group (original) was shown a card trick and asked for the solution. Another group (conditional) was shown the card trick and given a false solution, and then asked for the solution. They were then asked to think of an alternative solution, in case the one they reported was not correct. A third group (extinction) was given the false solution, asked for the solution, then received feedback that their solution was incorrect if they reported the false one. The outcome measure of interest was whether or not participants reported the correct solution.

------

#### Target outcomes: 
> Results from the first question of the original trick, without providing a false solution, show that 83% (25/30) of the participants found the correct solution (all the cards are the same), and none proposed the physical influence false solution. These results confirm that the correct solution of the trick is far more obvious than the physical influence false solution.

> As shown in Fig. 3a (see also Appendix A), there was a clear effect of the exposure to the false solution in the percentage of participants who discovered the correct solution after the first question. Results of chi-square tests showed that the percentage of participants who found the correct solution in the original trick group (83%) was significantly greater than both the percentage in the FS conditional trick group (17%, χ2 = 26.67, p < 0.001) and the percentage in the FS extinction trick group (13%, χ2 = 29.43, p < 0.001). Furthermore, for the two FS groups, participants who did not find the secret of the trick typically found solutions related to the false solution (e.g., “the card that the magician touched longer”). There is no significant difference between the percentage of participants who found the correct solution in the FS conditional trick group (17%) and the percentage in the FS extinction trick group (13%, χ2 = 0.13, p = 0.72).

> We next examined participants who did not initially solve the problem but then received the conditional or extinction test questions. Their results are shown in Fig. 3b (see also Appendix A). Results showed that the percentage of participants who found the correct solution in the conditional test question (20%) was significantly different from the percentage in the extinction test question (73%, χ2 = 14.41, p < 0.001) (for each condition, all the participants who answered “yes” for the first part of the test question found the correct solution).

------

```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)

# prepare an empty report object, we will update this each time we run compareValues2()
reportObject <- data.frame("Article_ID" = NA, "valuesChecked" = 0, "eyeballs" = 0, "Total_df" = 0, "Total_p" = 0, "Total_mean" = 0, "Total_sd" = 0, "Total_se" = 0, "Total_ci" = 0, "Total_bf" = 0, "Total_t" = 0, "Total_F" = 0, "Total_es" = 0, "Total_median" = 0, "Total_irr" = 0, "Total_r" = 0, "Total_z" = 0, "Total_coeff" = 0, "Total_n" = 0, "Total_x2" = 0, "Total_other" = 0, "Insufficient_Information_Errors" = 0, "Decision_Errors" = 0, "Major_Numerical_Errors" = 0, "Minor_Numerical_Errors" = 0, "Major_df" = 0, "Major_p" = 0, "Major_mean" = 0, "Major_sd" = 0, "Major_se" = 0, "Major_ci" = 0, "Major_bf" = 0, "Major_t" = 0, "Major_F" = 0, "Major_es" = 0, "Major_median" = 0, "Major_irr" = 0, "Major_r" = 0, "Major_z" = 0, "Major_coeff" = 0, "Major_n" = 0, "Major_x2" = 0, "Major_other" = 0, "affectsConclusion" = NA, "error_typo" = 0, "error_specification" = 0, "error_analysis" = 0, "error_data" = 0, "error_unidentified" = 0, "Author_Assistance" = NA, "resolved_typo" = 0, "resolved_specification" = 0, "resolved_analysis" = 0, "resolved_data" = 0, "correctionSuggested" = NA, "correctionPublished" = NA)
```

## Step 1: Load packages


```{r}
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(CODreports) # custom report functions
```

## Step 2: Load data

Data were supplied as a Microsoft Word files containing tables. I have copied the columns containing the outcome variable into a comma-separated file.

```{r}
data <- read.csv("data/data.csv")
```

## Step 4: Run analysis

### Descriptive statistics

> Results from the first question of the original trick, without providing a false solution, show that 83% (25/30) of the participants found the correct solution

```{r}
correct <- sum(data$firstquestion_original)
total <- length(data$firstquestion_original)
percentage <- 100 * correct/total

reportObject <- compareValues2("83", percentage, valueType = 'n')
reportObject <- compareValues2("25", correct, valueType = 'n')
reportObject <- compareValues2("30", total, valueType = 'n')
```

> We next examined participants who did not initially solve the problem but then received the conditional or extinction test questions. Their results are shown in Fig. 3b (see also Appendix A).

```{r, results = 'asis'}
table_out <- data.frame("Orig1" = c(paste(sum(data$firstquestion_original), "/", length(data$firstquestion_original), " ", round(100*sum(data$firstquestion_original)/length(data$firstquestion_original), 0), "%", sep = ""), NA, NA),
                        "Orig2" = c(paste(length(data$firstquestion_original) - sum(data$firstquestion_original), "/", length(data$firstquestion_original), " ", round(100*(length(data$firstquestion_original) - sum(data$firstquestion_original))/length(data$firstquestion_original), 0), "%", sep = ""), NA, NA),
                        "Cond1" = c(paste(sum(data$firstquestion_conditional), "/", length(data$firstquestion_conditional), " ", round(100*sum(data$firstquestion_conditional)/length(data$firstquestion_conditional), 0), "%", sep = ""), NA, NA),
                        "Cond2" = c(paste(length(data$firstquestion_conditional) - sum(data$firstquestion_conditional), "/", length(data$firstquestion_conditional), " ", round(100*(length(data$firstquestion_conditional) - sum(data$firstquestion_conditional))/length(data$firstquestion_conditional), 0), "%", sep = ""),                                         paste(table(data$testquestionfirst_conditional)[1], "/", sum(!is.na(data$testquestionfirst_conditional)), " ", round(100*table(data$testquestionfirst_conditional)[ 2]/sum(!is.na(data$testquestionfirst_conditional)), 0), "%", sep = ""), NA),
                        "Cond3" = c(NA, 
                                        paste(table(data$testquestionsecond_conditional)[2] , "/", sum(!is.na(data$testquestionsecond_conditional)) , " ", round(100*table(data$testquestionsecond_conditional)[2]/sum(!is.na(data$testquestionsecond_conditional)), 0), "%", sep = ""),
                                        paste(sum(data$testquestionsecond_conditional[data$testquestionfirst_conditional == 1], na.rm = T), "/", sum(!is.na(data$testquestionsecond_conditional[data$testquestionfirst_conditional == 1])), " ", round(100*sum(data$testquestionsecond_conditional[data$testquestionfirst_conditional == 1], na.rm = T)/sum(!is.na(data$testquestionsecond_conditional[data$testquestionfirst_conditional == 1])), 0), "%", sep = "")),
                        "Ext1" = c(paste(sum(data$firstquestion_extinction), "/", length(data$firstquestion_extinction), " ", round(100*sum(data$firstquestion_extinction)/length(data$firstquestion_extinction), 0), "%", sep = ""), NA, NA),
                        "Ext2" = c(paste(length(data$firstquestion_extinction) - sum(data$firstquestion_extinction), "/", length(data$firstquestion_extinction), " ", round(100*(length(data$firstquestion_extinction) - sum(data$firstquestion_extinction))/length(data$firstquestion_extinction), 0), "%", sep = ""),                                         paste(table(data$testquestionfirst_extinction)[1], "/", sum(!is.na(data$testquestionfirst_extinction)), " ", round(100*table(data$testquestionfirst_extinction)[ 2]/sum(!is.na(data$testquestionfirst_extinction)), 0), "%", sep = ""), NA),
                        "Ext3" = c(NA, 
                                        paste(table(data$testquestionsecond_extinction)[2] , "/", sum(!is.na(data$testquestionsecond_extinction)) , " ", round(100*table(data$testquestionsecond_extinction)[2]/sum(!is.na(data$testquestionsecond_extinction)), 0), "%", sep = ""),
                                        paste(sum(data$testquestionsecond_extinction[data$testquestionfirst_extinction == 1], na.rm = T), "/", sum(!is.na(data$testquestionsecond_extinction[data$testquestionfirst_extinction == 1])), " ", round(100*sum(data$testquestionsecond_extinction[data$testquestionfirst_extinction == 1], na.rm = T)/sum(!is.na(data$testquestionsecond_extinction[data$testquestionfirst_extinction == 1])), 0), "%", sep = "")))

rownames(table_out) <- c("First q", "Test q 1", "Test q 2")

kable(table_out, format = "markdown")

```

![Appendix A.](images/AppendixA.pnG)

The table contains 36 numerical results. Three of them were already reported in the text and compared above. Let's explictly check the others.

```{r}
reportObject <- compareValues2(reportedValue = "5", obtainedValue = 5, valueType = "n")
reportObject <- compareValues2(reportedValue = "30", obtainedValue = 30, valueType = "n")
reportObject <- compareValues2(reportedValue = "17", obtainedValue = 17, valueType = "n")
reportObject <- compareValues2(reportedValue = "5", obtainedValue = 5, valueType = "n")
reportObject <- compareValues2(reportedValue = "30", obtainedValue = 30, valueType = "n")
reportObject <- compareValues2(reportedValue = "17", obtainedValue = 17, valueType = "n")
reportObject <- compareValues2(reportedValue = "25", obtainedValue = 25, valueType = "n")
reportObject <- compareValues2(reportedValue = "30", obtainedValue = 30, valueType = "n")
reportObject <- compareValues2(reportedValue = "83", obtainedValue = 83, valueType = "n")
reportObject <- compareValues2(reportedValue = "4", obtainedValue = 4, valueType = "n")
reportObject <- compareValues2(reportedValue = "30", obtainedValue = 30, valueType = "n")
reportObject <- compareValues2(reportedValue = "13", obtainedValue = 13, valueType = "n")
reportObject <- compareValues2(reportedValue = "26", obtainedValue = 26, valueType = "n")
reportObject <- compareValues2(reportedValue = "30", obtainedValue = 30, valueType = "n")
reportObject <- compareValues2(reportedValue = "87", obtainedValue = 87, valueType = "n")
reportObject <- compareValues2(reportedValue = "20", obtainedValue = 20, valueType = "n")
reportObject <- compareValues2(reportedValue = "25", obtainedValue = 25, valueType = "n")
reportObject <- compareValues2(reportedValue = "80", obtainedValue = 80, valueType = "n")
reportObject <- compareValues2(reportedValue = "5", obtainedValue = 5, valueType = "n")
reportObject <- compareValues2(reportedValue = "25", obtainedValue = 25, valueType = "n")
reportObject <- compareValues2(reportedValue = "20", obtainedValue = 20, valueType = "n")
reportObject <- compareValues2(reportedValue = "7", obtainedValue = 7, valueType = "n")
reportObject <- compareValues2(reportedValue = "26", obtainedValue = 26, valueType = "n")
reportObject <- compareValues2(reportedValue = "27", obtainedValue = 27, valueType = "n")
reportObject <- compareValues2(reportedValue = "19", obtainedValue = 19, valueType = "n")
reportObject <- compareValues2(reportedValue = "26", obtainedValue = 26, valueType = "n")
reportObject <- compareValues2(reportedValue = "73", obtainedValue = 73, valueType = "n")
reportObject <- compareValues2(reportedValue = "5", obtainedValue = 5, valueType = "n")
reportObject <- compareValues2(reportedValue = "5", obtainedValue = 5, valueType = "n")
reportObject <- compareValues2(reportedValue = "100", obtainedValue = 100, valueType = "n")
reportObject <- compareValues2(reportedValue = "19", obtainedValue = 19, valueType = "n")
reportObject <- compareValues2(reportedValue = "19", obtainedValue = 19, valueType = "n")
reportObject <- compareValues2(reportedValue = "100", obtainedValue = 100, valueType = "n")
```

### Inferential statistics
> Results of chi-square tests showed that the percentage of participants who found the correct solution in the original trick group (83%) was significantly greater than both the percentage in the FS conditional trick group (17%, χ2 = 26.67, p < 0.001) and the percentage in the FS extinction trick group (13%, χ2 = 29.43, p < 0.001).

> There is no significant difference between the percentage of participants who found the correct solution in the FS conditional trick group (17%) and the percentage in the FS extinction trick group (13%, χ2 = 0.13, p = 0.72).

Percentages in the above text quotes are already covered in the descriptive analyses section above and will not be covered again here.

```{r}
# Test original versus conditional
table1 <- rbind(table(data$firstquestion_original), table(data$firstquestion_conditional))
test1 <- chisq.test(table1, correct = FALSE)

# Compare values for original versus conditional
reportObject <- compareValues2("26.67", test1$statistic, valueType = 'x2')
reportObject <- compareValues2("eyeballMATCH", test1$p.value, valueType = 'p')

# Test original versus extinction
table2 <- rbind(table(data$firstquestion_original), table(data$firstquestion_extinction))
test2 <- chisq.test(table2, correct = FALSE)

# Compare values for original versus extinction
reportObject <- compareValues2("29.43", test2$statistic, valueType = 'x2')
reportObject <- compareValues2("eyeballMATCH", test2$p.value, valueType = 'p')

# Test conditional versus extinction
table3 <- rbind(table(data$firstquestion_conditional), table(data$firstquestion_extinction))
test3 <- chisq.test(table3, correct = FALSE)

# Compare values for conditional versus extinction
reportObject <- compareValues2("0.13", test3$statistic, valueType = 'x2')
reportObject <- compareValues2("0.72", test3$p.value, valueType = 'p')
```
Where p-values were reported as inequalities, I compared them by eyeballing, resulting in MATCH for original vs conditional and MATCH for original vs extinction.

NB: No continuity correction was performed for the $\chi^2$ tests. 

> Results showed that the percentage of participants who found the correct solution in the conditional test question (20%) was significantly different from the percentage in the extinction test question (73%, χ2 = 14.41, p < 0.001) (for each condition, all the participants who answered “yes” for the first part of the test question found the correct solution).

```{r}
# Test conditional versus extinction
table4 <- rbind(table(data$testquestionfirst_conditional), table(data$testquestionfirst_extinction))
test4 <- chisq.test(table4, correct = FALSE)

# Compare values for conditional versus extinction
reportObject <- compareValues2("14.41", test4$statistic, valueType = 'x2')
reportObject <- compareValues2("eyeballMATCH", test4$p.value, valueType = 'p')
```

The p-value was reported as an inequality, and I compared by eyeballing, resulting in MATCH.

## Step 5: Conclusion

All descriptive results matched. Results from chi-squared tests matched as well. 

```{r}
reportObject$Article_ID <- "leydV"
reportObject$affectsConclusion <- NA
reportObject$error_typo <- 0
reportObject$error_specification <- 0
reportObject$error_analysis <- 0
reportObject$error_data <- 0
reportObject$error_unidentified <- 0
reportObject$Author_Assistance <- F
reportObject$resolved_typo <- 0
reportObject$resolved_specification <- 0
reportObject$resolved_analysis <- 0
reportObject$resolved_data <- 0
reportObject$correctionSuggested <- NA
reportObject$correctionPublished <- NA

# decide on final outcome
if(reportObject$Decision_Errors > 0 | reportObject$Major_Numerical_Errors > 0 | reportObject$Insufficient_Information_Errors > 0){
  reportObject$finalOutcome <- "Failure"
  if(reportObject$Author_Assistance == T){
    reportObject$finalOutcome <- "Failure despite author assistance"
  }
}else{
  reportObject$finalOutcome <- "Success"
  if(reportObject$Author_Assistance == T){
    reportObject$finalOutcome <- "Success with author assistance"
  }
}

# save the report object
filename <- paste0("reportObject_", reportObject$Article_ID,".csv")
write_csv(reportObject, filename)
```

## Report Object

```{r, echo = FALSE}
# display report object in chunks
kable(reportObject[2:10], align = 'l')
kable(reportObject[11:20], align = 'l')
kable(reportObject[21:25], align = 'l')
kable(reportObject[26:30], align = 'l')
kable(reportObject[31:35], align = 'l')
kable(reportObject[36:40], align = 'l')
kable(reportObject[41:45], align = 'l')
kable(reportObject[46:51], align = 'l')
kable(reportObject[52:57], align = 'l')
```

## Session information

```{r session_info, include=TRUE, echo=TRUE, results='markup'}
devtools::session_info()
```
